# -*- coding: utf-8 -*-
"""What Are Those CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_HsahGyx9l1u-2ARHzpiM7w16V_cdNad
"""

# Commented out IPython magic to ensure Python compatibility.
#Display and plotting imports
# %pylab inline 
import seaborn as sns
sns.set()
from IPython.display import SVG

import pandas as pd

#######################
# standard code block #
#######################

# see https://ipython.readthedocs.io/en/stable/interactive/magics.html
# %pylab inline

# sets backend to render higher res images
# %config InlineBackend.figure_formats = ['retina']

#######################
#       imports       #
#######################

from keras.applications.vgg16 import VGG16
from keras.applications.imagenet_utils import decode_predictions

from keras.models import Model, Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten

#Note I exclude the final dense layers by setting include_top=False,
#and add new ones to train from scratch below
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)) 
 
#Freeze convolutional layers
for layer in base_model.layers:
    layer.trainable = False    

#Establish new fully connected block
x = base_model.output
x = Flatten()(x)  # flatten from convolution tensor output  
x = Dense(500, activation='relu')(x) # number of layers and units are hyperparameters, as usual
x = Dense(500, activation='relu')(x)
predictions = Dense(6, activation='softmax')(x) # should match # of classes predicted

#This is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

from keras.preprocessing.image import ImageDataGenerator

#This is the augmentation configuration used for training
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

#This is the augmentation configuration used for testing:
# only rescaling
valid_datagen = ImageDataGenerator(rescale=1./255)

#Flow from directory command in Keras
#This is a generator that will read pictures found in subfolers of 'Train'
train_generator = train_datagen.flow_from_directory(
    directory=r"/content/drive/My Drive/Train",                #This is the target directory
    target_size=(224, 224),                                    #All images will be resized to 224x224
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",                                  #Since we use categorical_crossentropy loss, we need categorical labels
    shuffle=True,
    seed=42
)

#Flow from directory command in Keras
#This is a generator that will read pictures found in subfolers of 'Validation'
valid_generator = valid_datagen.flow_from_directory(
    directory=r"/content/drive/My Drive/Validation",          #This is the target directory
    target_size=(224, 224),                                   #All images will be resized to 224x224
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",                                 #Since we use categorical_crossentropy loss, we need categorical labels
    shuffle=True,
    seed=42
)

#Flow from directory command in Keras
#This is a generator that will read pictures found in subfolers of 'Test'
test_datagen = ImageDataGenerator()

test_generator = test_datagen.flow_from_directory(
    directory=r"/content/drive/My Drive/Test",
    target_size=(224, 224),
    color_mode="rgb",
    batch_size=1,
    class_mode="categorical",
    shuffle=False,
    seed=42
)

#Fitting/Training the model
STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size

STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size

history = model.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=valid_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=5
)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Accuracy vs. Training Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train','Validation']);

#Targeted Categories (numerical labels)
true_classes = valid_generator.classes

#Targeted Categories (labels)
class_labels = list(valid_generator.class_indices.keys())

#Sklearn confusion matrix
#Model Accuracy metrics
from sklearn.metrics import classification_report, confusion_matrix

#Confution Matrix and Classification Report
Y_pred = model.predict_generator(valid_generator)
y_pred = np.argmax(Y_pred, axis=1)

cm = confusion_matrix(valid_generator.classes, y_pred)
print('Confusion Matrix')
print(confusion_matrix(valid_generator.classes, y_pred))
print('Classification Report')

class_labels = list(valid_generator.class_indices.keys())  
print(classification_report(valid_generator.classes, y_pred, target_names = class_labels))

class_labels

#cnn_pred_cifar = model.predict(x_test)
Y_pred = model.predict_generator(valid_generator)

#cnn_pred_cifar = np.argmax(cnn_pred_cifar,axis=1)
y_pred = np.argmax(Y_pred, axis=1)


#y_true = np.argmax(y_test_tf,axis=1)
y_true = np.argmax(valid_generator.classes ,axis=0)

import itertools
import numpy as np
import matplotlib.pyplot as plt

#Function to generate Confusion Matrix
def plot_confusion_matrix2(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#Confusion Matrix
plt.figure(figsize=(8,8))
plot_confusion_matrix2(cm, class_labels)

from keras.models import Model
import keras
inter_model = keras.Model(model.input, model.layers[-2].output)
inter_output = inter_model.predict_generator(test_generator)

shoe_name = test_generator.filenames

#Get vector from CNN and pass through pair wise distance
from sklearn.metrics import pairwise_distances
d = pairwise_distances(inter_output,metric='cosine')

[shoe_name[m] for m in d[80].argsort()[:20]] #for Sneaker #1

#Get probabilities for each class
proba = model.predict(valid_generator)        

#Get class names for top 10 categories
sorted_categories = np.argsort(proba[0])[:-7:-1]

#Print classes and corresponding probabilities
for i in range(6):
    print("{}".format(class_labels[sorted_categories[i]])+" ({:.3})".format(proba[0][sorted_categories[i]]))

